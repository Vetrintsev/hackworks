{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск повторных событий в массиве событий\n",
    "Ключевая функция **convert_to_repeats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import time, datetime\n",
    "\n",
    "def progress_it(func, total_count):\n",
    "    \n",
    "    count_current = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    prev_time = start_time\n",
    "    \n",
    "    def next_step(*args, **kwargs):\n",
    "        \n",
    "        nonlocal count_current\n",
    "        nonlocal prev_time\n",
    "        count_current += 1\n",
    "        \n",
    "        now_time = time.time()\n",
    "        \n",
    "        \n",
    "        if (now_time - prev_time) > 1:\n",
    "            prev_time = now_time\n",
    "            progress = count_current/total_count\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            display('Iterations {:.0f} Progress: {:.2%} Completion time: {}'.format(\n",
    "                count_current, \n",
    "                progress,\n",
    "                datetime.datetime.fromtimestamp(\n",
    "                    start_time + (now_time - start_time) / progress\n",
    "                ).strftime('%B %d %H:%M')\n",
    "            ))\n",
    "        \n",
    "        return func(*args, **kwargs)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "            \n",
    "    display('Iterations {:.0f} Progress: {:.2%} Completion time: {}'.format(\n",
    "        0, \n",
    "        0,\n",
    "        '...'\n",
    "    ))\n",
    "    \n",
    "    return next_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode(df, date_column, episode_columns):\n",
    "    \n",
    "    data = [df[date_column].min(), None]\n",
    "    \n",
    "    for col in episode_columns:\n",
    "        if type(col) is str:\n",
    "            data.append(\n",
    "                '; '.join([\n",
    "                    str(item)\n",
    "                    for item in sorted([\n",
    "                        el for el in list(df[col].unique()) if el not in [None, np.nan, np.NAN, np.NaN, pd.tslib.NaT]\n",
    "                    ])\n",
    "                ])\n",
    "            )\n",
    "        \n",
    "        elif type(col) is dict:\n",
    "            key, func = list(col.items())[0]\n",
    "            if type(func) is str:\n",
    "                data.append(df[key].agg(func))\n",
    "            \n",
    "            else:\n",
    "                data.append(func(df[key]))\n",
    "        \n",
    "        else:\n",
    "            data.append(\n",
    "                '\\n'.join([\n",
    "                    ' | '.join([item for item in row if type(item) is str])\n",
    "                    for row in df[col].drop_duplicates().sort_values(col[0]).to_dict('split')['data']\n",
    "                ])\n",
    "            )\n",
    "    \n",
    "    return pd.DataFrame([[data]], columns = ['episode_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repeats(\n",
    "    df, \n",
    "    leader_columns,\n",
    "    date_column,\n",
    "    episode_group_by,\n",
    "    episode_columns,\n",
    "    max_episode_length,\n",
    "    min_episode_length,\n",
    "    episode_from_start,\n",
    "    max_days_between\n",
    "):\n",
    "    episode_items = sorted(\n",
    "        [\n",
    "            item\n",
    "            for row in df.groupby(episode_group_by).apply(\n",
    "                get_episode, date_column, episode_columns\n",
    "            ).to_dict('split')['data']\n",
    "            for item in row\n",
    "        ],\n",
    "        key = lambda x: x[0], \n",
    "        reverse = not episode_from_start\n",
    "    )\n",
    "    \n",
    "    max_hours = max_days_between * 24\n",
    "    \n",
    "    episodes = []\n",
    "    episode = []\n",
    "    \n",
    "    episode = [episode_items[0]]\n",
    "    \n",
    "    for item in episode_items[1:]:\n",
    "        diff = abs((episode[-1][0] - item[0]).total_seconds()/3600)\n",
    "        if diff <= max_hours:\n",
    "            item[1] = diff\n",
    "            episode.append(item)\n",
    "        \n",
    "        else:\n",
    "            if len(episode) >= min_episode_length: episodes.append(episode[:max_episode_length])\n",
    "            episode = [item]\n",
    "    \n",
    "    if len(episode) >= min_episode_length: episodes.append(episode[:max_episode_length])\n",
    "    \n",
    "    data = []\n",
    "    leaders_data = list(df[leader_columns].iloc[0].values)\n",
    "    max_columns_count = len(leader_columns) + (len(episode_columns) + 2) * max_episode_length\n",
    "    \n",
    "    for episode in episodes:\n",
    "        row = leaders_data.copy()\n",
    "        \n",
    "        for item in episode:\n",
    "            row.extend(item)\n",
    "        \n",
    "        row.extend( [None] * (max_columns_count - len(row)) )\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    episode_column_names = [date_column, 'Прошло времени, час.'] + [\n",
    "        name if type(name) is str else (\n",
    "            list(name.keys())[0] if type(name) is dict else ' | '.join([str(s) for s in name])\n",
    "        )\n",
    "        for name in episode_columns\n",
    "    ]\n",
    "    \n",
    "    names = leader_columns + [ \n",
    "        'Эл.{:.0f}: {}'.format(prefix + 1, name)\n",
    "        for prefix in range(max_episode_length)\n",
    "        for name in episode_column_names\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(data = data, columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_format(book, fmt):\n",
    "    properties = [f[4:] for f in dir(fmt) if f[0:4] == 'set_']\n",
    "    dft_fmt = book.add_format()\n",
    "    return book.add_format({k : v for k, v in fmt.__dict__.iteritems() if k in properties and dft_fmt.__dict__[k] != v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_formats(book, *fmts):\n",
    "    properties = [f[4:] for fmt in fmts for f in dir(fmt) if f[0:4] == 'set_']\n",
    "    dft_fmt = book.add_format()\n",
    "    return book.add_format(\n",
    "        dict([\n",
    "            (k, v)\n",
    "            for fmt in fmts\n",
    "            for k, v in fmt.__dict__.items() if k in properties and dft_fmt.__dict__[k] != v\n",
    "        ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xlsxwiter_formats(df, workbook):\n",
    "    \n",
    "    fdatetime = workbook.add_format({'num_format':'dd.mm.yyyy HH:MM', 'align':'left', 'border':4})\n",
    "    ffloat = workbook.add_format({'num_format':'0.0', 'align':'right', 'border':4})\n",
    "    fint = workbook.add_format({'num_format':'0', 'align':'right', 'border':4})\n",
    "    fdef = workbook.add_format()\n",
    "    \n",
    "    formats = []\n",
    "    \n",
    "    for col in df.columns.tolist():\n",
    "        t = df.dtypes[col].type\n",
    "        \n",
    "        if t in [np.datetime64, datetime.datetime]:\n",
    "            formats.append(fdatetime)\n",
    "        \n",
    "        elif t in [np.float, np.float16, np.float32, np.float64, np.float_, np.float_power]:\n",
    "            formats.append(ffloat)\n",
    "        \n",
    "        elif t in [np.int, np.int0, np.int16, np.int32, np.int64, np.int8, np.int_]:\n",
    "            formats.append(fint)\n",
    "        \n",
    "        else:\n",
    "            formats.append(fdef)\n",
    "    \n",
    "    return formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_repeats(\n",
    "    df,\n",
    "    group_by,\n",
    "    leader_columns,\n",
    "    date_column,\n",
    "    episode_group_by,\n",
    "    episode_columns,\n",
    "    max_episode_length,\n",
    "    min_episode_length = 2,\n",
    "    episode_from_start = True,\n",
    "    max_days_between = 32,\n",
    "    to_excel_file = None\n",
    "):\n",
    "    \"\"\"\n",
    "    convert_to_repeats(\n",
    "        df, group_by, leader_columns, date_column, \n",
    "        episode_group_by, episode_columns, max_episode_length, \n",
    "        min_episode_length = 2, episode_from_start = True, \n",
    "        max_days_between = 32, to_excel_file = None\n",
    "    )\n",
    "    Объединяет повторяющиеся события в строку. \n",
    "    Одна строка - один эпизод. В строке несколько инцидентов. \n",
    "    Возможно объединение нескольких инцидентов в один по общему признаку.\n",
    "    \n",
    "    Returns: pandas.DataFrame\n",
    "    \n",
    "    Аргументы:\n",
    "    \n",
    "    df - pandas.DataFrame\n",
    "    \n",
    "    group_by - список названий столбцов, по которым производить базовую \n",
    "        группировку (например, по клиенту, или по тематике и т.д.):\n",
    "        group_by = ['ИНН', 'Тема обращения']\n",
    "    \n",
    "    leader_columns - список названий столбцов, первые столбцы вывода, \n",
    "        они будут выгружены в итоговую таблицу (берется первое \n",
    "        значение из каждой группы):\n",
    "        leader_columns = ['ИНН', 'Наименование организации', 'Тема обращения']\n",
    "    \n",
    "    date_column - столбец дат (и времени), по которому определяется \n",
    "        является ли одно событие повторным по отношению к другому \n",
    "        в заданный промежуток времени.\n",
    "        date_column = 'Дата и время звонка'\n",
    "    \n",
    "    episode_group_by - список названий столбцов, по которым группировать \n",
    "        инциденты внутри эпизода (например, по идентификатору звонка).\n",
    "        episode_group_by = ['ID звонка']\n",
    "    \n",
    "    episode_columns - список определений столбцов, которые надо вывести \n",
    "        по каждому инциденту:\n",
    "        episode_columns = [\n",
    "            \n",
    "            'Номер обращения', \n",
    "            # будут выгружены через \";\" список уникальных значений \n",
    "            # по группе инцидента. В данном примере - если \n",
    "            # по одному 'ID звонка' создалось два обращения, \n",
    "            # их номера будут перечислены через точку с запятой.\n",
    "            \n",
    "            ['Тема обращения', 'Подтема обращения'], \n",
    "            # будут выгружены уникальные сочетания перечисленных столбцов, \n",
    "            # значения столбцов разделены знаком \"|\", сами сочетания знаком \";\".\n",
    "            \n",
    "            {'Продолжительность', 'max'}, \n",
    "            # для указанного в ключе столбца будет вызвана указанная \n",
    "            # в значении функция агрегации относительно выборки по инциденту.\n",
    "            # В данном случае это тождественно \n",
    "            # value = df.groupby(...)['Продолжительность'].agg('max')\n",
    "            # т.е. для столбца 'Продолжительность' будет посчитано максимальное его значение.\n",
    "            \n",
    "            {'Продолжительность', func},\n",
    "            # для указанного в ключе столбца будет вызвана переданная \n",
    "            # в значении функция. В функцию будет передан объект \n",
    "            # pandas.Series с элементами в группе инцидента.\n",
    "            # В данном случае это тождественно \n",
    "            # value = func( df.groupby(...)['Продолжительность'] )\n",
    "            \n",
    "            ... ]\n",
    "            \n",
    "    max_episode_length - число, максимальная глубина повторений.\n",
    "        При этом, важно понимать, если глубина всего эпизода,\n",
    "        например, 8 повторений, а ограничение max_episode_length = 5,\n",
    "        то выведено будет 5 элементов, при этом информация об\n",
    "        оставшихся 3-х элементах будет отброшена.\n",
    "    \n",
    "    min_episode_length - число, минимально допустимая глубина повторения,\n",
    "        если повторений будет меньше - данные будут отброшены.\n",
    "    \n",
    "    episode_from_start - True или False, определяет порядок сортировки инцидентов\n",
    "        внутри эпизода. Если episode_from_start = True, то первым инцидентом в выводе\n",
    "        будет самый первый инцидент по хронологии, иначе первым инцидентом в выводе\n",
    "        будет самый последний инцидент в эпизоде, вторым - предпоследний и т.д.\n",
    "    \n",
    "    max_days_between - число, максимальный промежуток времени между двумя инцидентами,\n",
    "        в пределах которого инцидент считается повторным по отношению к предыдущему.\n",
    "    \n",
    "    to_excel_file - текст, наименование файла с расширением .xlsx, \n",
    "        в который автоматически будет экспортирован вывод с форматированием.\n",
    "        Если to_excel_file = None (по умолчанию) - то экспорт будет проигнорирован.\n",
    "        to_excel_file = 'Some Excel filename.xlsx'\n",
    "    \n",
    "    Важно:\n",
    "    \n",
    "    Будут удалены все строки, содержащие пустые значения хотя бы в одной \n",
    "    ячейке столбцов group_by и episode_group_by.\n",
    "    \n",
    "    \"\"\"\n",
    "    g = df.dropna(subset = group_by + episode_group_by).groupby(group_by, as_index = False)\n",
    "    \n",
    "    g_df = g.apply(\n",
    "        progress_it(get_repeats, len(g)), \n",
    "        leader_columns, \n",
    "        date_column, \n",
    "        episode_group_by, \n",
    "        episode_columns, \n",
    "        max_episode_length, \n",
    "        min_episode_length,\n",
    "        episode_from_start,\n",
    "        max_days_between\n",
    "    )\n",
    "    \n",
    "    if to_excel_file is not None:\n",
    "        print('Сохранение в файл {}...'.format(to_excel_file))\n",
    "\n",
    "        sheet_name = 'Лист1'\n",
    "        writer = pd.ExcelWriter(to_excel_file, engine = 'xlsxwriter')\n",
    "        \n",
    "        book  = writer.book\n",
    "        sheet = book.add_worksheet(sheet_name)\n",
    "        \n",
    "        formats = get_xlsxwiter_formats(g_df, book)\n",
    "        fheaders = [book.add_format({'bold':True, 'align':'center', 'valign':'vcenter', 'text_wrap':True, 'border':1})] * len(formats)\n",
    "        fevencol = book.add_format({'bg_color':'silver'})\n",
    "        \n",
    "        first_col_idx = len(leader_columns)\n",
    "        episode_columns_count = (len(g_df.columns) - first_col_idx) / max_episode_length\n",
    "        for col_idx_range in range(0, max_episode_length, 2):\n",
    "            for col_idx in range(\n",
    "                int(first_col_idx + col_idx_range*episode_columns_count), \n",
    "                int(first_col_idx + col_idx_range*episode_columns_count + episode_columns_count)\n",
    "            ):\n",
    "                formats[col_idx] = combine_formats(book, formats[col_idx], fevencol)\n",
    "                fheaders[col_idx] = combine_formats(book, fheaders[col_idx], fevencol)\n",
    "        \n",
    "        \n",
    "        for col_index, value in enumerate([\n",
    "            col if type(col) is str else '. '.join(list(col))\n",
    "            for col in g_df.columns.tolist()\n",
    "        ]):\n",
    "            sheet.write(0, col_index, value, fheaders[col_index])\n",
    "        \n",
    "        for row_index, data in enumerate(g_df.itertuples(False), 1):\n",
    "            for col_index, value in enumerate(data):\n",
    "                if (value != value) or (value == np.inf): value = None\n",
    "                sheet.write(row_index, col_index, value, formats[col_index])\n",
    "\n",
    "        writer.save()\n",
    "\n",
    "        print('Сохранение завершено.')\n",
    "        \n",
    "    return g_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
